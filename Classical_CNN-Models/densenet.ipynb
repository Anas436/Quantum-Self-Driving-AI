{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-18T13:44:10.971520Z","iopub.execute_input":"2023-07-18T13:44:10.971841Z","iopub.status.idle":"2023-07-18T13:44:10.986712Z","shell.execute_reply.started":"2023-07-18T13:44:10.971813Z","shell.execute_reply":"2023-07-18T13:44:10.985246Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/raghav-thiruv/Omdena-Quantum-Self-Driving.git","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:44:10.989660Z","iopub.execute_input":"2023-07-18T13:44:10.990170Z","iopub.status.idle":"2023-07-18T13:45:37.934889Z","shell.execute_reply.started":"2023-07-18T13:44:10.990133Z","shell.execute_reply":"2023-07-18T13:45:37.933611Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'Omdena-Quantum-Self-Driving'...\nremote: Enumerating objects: 45889, done.\u001b[K\nremote: Counting objects: 100% (11799/11799), done.\u001b[K\nremote: Compressing objects: 100% (11746/11746), done.\u001b[K\nremote: Total 45889 (delta 94), reused 11715 (delta 43), pack-reused 34090\u001b[K\nReceiving objects: 100% (45889/45889), 2.16 GiB | 36.71 MiB/s, done.\nResolving deltas: 100% (123/123), done.\nUpdating files: 100% (45596/45596), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport keras\nimport random\nimport math\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\nfrom tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nfrom keras import layers\n\nfrom keras import models\n\nfrom keras.layers import (Input, Dense, Activation, ZeroPadding2D,\nBatchNormalization, Flatten, Conv2D, concatenate, Lambda)\n\nfrom keras.layers import (AveragePooling2D, MaxPooling2D, Dropout,\nGlobalMaxPooling2D, GlobalAveragePooling2D)\n\nfrom keras.models import Model, load_model\nfrom keras import regularizers, optimizers\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:37.937030Z","iopub.execute_input":"2023-07-18T13:45:37.937446Z","iopub.status.idle":"2023-07-18T13:45:48.668551Z","shell.execute_reply.started":"2023-07-18T13:45:37.937407Z","shell.execute_reply":"2023-07-18T13:45:48.667439Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"from struct import unpack\nfrom tqdm import tqdm\nimport os\n\nimg_dir = '/content/Omdena-Quantum-Self-Driving/Images/driving_dataset1/'\nroot_img = '/content/Omdena-Quantum-Self-Driving/Images/driving_dataset1/'\nmarker_mapping = {\n    0xffd8: \"Start of Image\",\n    0xffe0: \"Application Default Header\",\n    0xffdb: \"Quantization Table\",\n    0xffc0: \"Start of Frame\",\n    0xffc4: \"Define Huffman Table\",\n    0xffda: \"Start of Scan\",\n    0xffd9: \"End of Image\"\n}\n\n\nclass JPEG:\n    def __init__(self, image_file):\n        with open(image_file, 'rb') as f:\n            self.img_data = f.read()\n\n    def decode(self):\n        data = self.img_data\n        while(True):\n            marker, = unpack(\">H\", data[0:2])\n            # print(marker_mapping.get(marker))\n            if marker == 0xffd8:\n                data = data[2:]\n            elif marker == 0xffd9:\n                return\n            elif marker == 0xffda:\n                data = data[-2:]\n            else:\n                lenchunk, = unpack(\">H\", data[2:4])\n                data = data[2+lenchunk:]\n            if len(data)==0:\n               raise TypeError(\"issue reading jpeg file\")\n\n\nbads = []\n\nfor dirName, subdirList, fileList in os.walk(img_dir):\n    imagesList = fileList\n    for img in tqdm(imagesList):\n      image = os.path.join(root_img,img)\n      image = JPEG(image)\n      try:\n        image.decode()\n      except:\n        bads.append(img)\n\n\nfor name in bads:\n  os.remove(os.path.join(root_img,name))","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:48.670016Z","iopub.execute_input":"2023-07-18T13:45:48.670942Z","iopub.status.idle":"2023-07-18T13:45:48.685123Z","shell.execute_reply.started":"2023-07-18T13:45:48.670900Z","shell.execute_reply":"2023-07-18T13:45:48.683964Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:48.689463Z","iopub.execute_input":"2023-07-18T13:45:48.689944Z","iopub.status.idle":"2023-07-18T13:45:49.709764Z","shell.execute_reply.started":"2023-07-18T13:45:48.689909Z","shell.execute_reply":"2023-07-18T13:45:49.708382Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Omdena-Quantum-Self-Driving  __notebook_source__.ipynb\n","output_type":"stream"}]},{"cell_type":"code","source":"!mv \"Omdena-Quantum-Self-Driving/Images/driving_dataset1/data.txt\" \"Omdena-Quantum-Self-Driving/Images/\"","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:49.712062Z","iopub.execute_input":"2023-07-18T13:45:49.712470Z","iopub.status.idle":"2023-07-18T13:45:50.724636Z","shell.execute_reply.started":"2023-07-18T13:45:49.712434Z","shell.execute_reply":"2023-07-18T13:45:50.723216Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load steering angles from text file\ndf = pd.read_csv('Omdena-Quantum-Self-Driving/Images/data.txt', names=['filename', 'steering_angle'], delimiter=' ')\nimage_dir = 'Omdena-Quantum-Self-Driving/Images/driving_dataset1/'\ndata_file = \"Omdena-Quantum-Self-Driving/Images/data.txt\"\ndf['filename'] = df['filename'].apply(lambda x: os.path.join(image_dir, x))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:50.726689Z","iopub.execute_input":"2023-07-18T13:45:50.727431Z","iopub.status.idle":"2023-07-18T13:45:50.906131Z","shell.execute_reply.started":"2023-07-18T13:45:50.727393Z","shell.execute_reply":"2023-07-18T13:45:50.904955Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            filename  steering_angle\n0  Omdena-Quantum-Self-Driving/Images/driving_dat...             0.0\n1  Omdena-Quantum-Self-Driving/Images/driving_dat...             0.0\n2  Omdena-Quantum-Self-Driving/Images/driving_dat...             0.0\n3  Omdena-Quantum-Self-Driving/Images/driving_dat...             0.0\n4  Omdena-Quantum-Self-Driving/Images/driving_dat...             0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>steering_angle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Omdena-Quantum-Self-Driving/Images/driving_dat...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Omdena-Quantum-Self-Driving/Images/driving_dat...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Omdena-Quantum-Self-Driving/Images/driving_dat...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Omdena-Quantum-Self-Driving/Images/driving_dat...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Omdena-Quantum-Self-Driving/Images/driving_dat...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def load_image(image_path):\n    try:\n        image = tf.io.read_file(image_path)\n        image = tf.image.decode_jpeg(image, channels=3)\n        image = tf.image.resize(image, (224, 224))\n        image = tf.keras.applications.resnet.preprocess_input(image)\n    except:\n        print(f\"Invalid image format, skipping: {image_path}\")\n        return None\n    return image\n\ndef create_dataset(df):\n    image_dataset = tf.data.Dataset.from_tensor_slices(df['filename'])\n    angle_dataset = tf.data.Dataset.from_tensor_slices(df['steering_angle'])\n    image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n    image_dataset = image_dataset.apply(tf.data.experimental.ignore_errors())\n    dataset = tf.data.Dataset.zip((image_dataset, angle_dataset))\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:50.907851Z","iopub.execute_input":"2023-07-18T13:45:50.908300Z","iopub.status.idle":"2023-07-18T13:45:50.918094Z","shell.execute_reply.started":"2023-07-18T13:45:50.908258Z","shell.execute_reply":"2023-07-18T13:45:50.916921Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def densenet_model(input_shape):\n    \n    x_input = Input(shape=input_shape)\n    x = Lambda(lambda x: x/127.5-1.0)(x_input)\n    \n    x = Conv2D(32,(3,3),activation='relu',padding='same')(x_input)\n    \n    x = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n    \n    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n       \n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = Dense(256)(x)\n    x = Dense(64)(x)\n    x = Dense(1)(x)\n    \n    model = Model(inputs=x_input,outputs=x,name='model')\n    return model\n\nmodel = densenet_model((224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:50.919835Z","iopub.execute_input":"2023-07-18T13:45:50.920231Z","iopub.status.idle":"2023-07-18T13:45:54.537377Z","shell.execute_reply.started":"2023-07-18T13:45:50.920193Z","shell.execute_reply":"2023-07-18T13:45:54.536059Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"validation_split = 0.1\ndf = df.sample(frac=1).reset_index(drop=True)\nval_df = df[:int(validation_split*len(df))]\ntrain_df = df[int(validation_split*len(df)):]\n\ntrain_dataset = create_dataset(train_df)\nval_dataset = create_dataset(val_df)\n\nbatch_size = 32\ntrain_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\nval_dataset = val_dataset.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:54.538641Z","iopub.execute_input":"2023-07-18T13:45:54.539021Z","iopub.status.idle":"2023-07-18T13:45:54.744818Z","shell.execute_reply.started":"2023-07-18T13:45:54.538984Z","shell.execute_reply":"2023-07-18T13:45:54.743826Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:54.746113Z","iopub.execute_input":"2023-07-18T13:45:54.746446Z","iopub.status.idle":"2023-07-18T13:45:54.809995Z","shell.execute_reply.started":"2023-07-18T13:45:54.746416Z","shell.execute_reply":"2023-07-18T13:45:54.809204Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n conv2d (Conv2D)             (None, 224, 224, 32)      896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 224, 224, 32)      9248      \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n )                                                               \n                                                                 \n conv2d_2 (Conv2D)           (None, 112, 112, 64)      18496     \n                                                                 \n conv2d_3 (Conv2D)           (None, 112, 112, 64)      36928     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n 2D)                                                             \n                                                                 \n conv2d_4 (Conv2D)           (None, 56, 56, 128)       73856     \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dropout (Dropout)           (None, 25088)             0         \n                                                                 \n batch_normalization (BatchN  (None, 25088)            100352    \n ormalization)                                                   \n                                                                 \n dense (Dense)               (None, 512)               12845568  \n                                                                 \n dense_1 (Dense)             (None, 256)               131328    \n                                                                 \n dense_2 (Dense)             (None, 64)                16448     \n                                                                 \n dense_3 (Dense)             (None, 1)                 65        \n                                                                 \n=================================================================\nTotal params: 13,380,769\nTrainable params: 13,330,593\nNon-trainable params: 50,176\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Define early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\n# Define learning rate scheduler\nlr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n\n# Fit the model\nmodel.fit(train_dataset, validation_data=val_dataset, epochs=50, callbacks=[early_stopping, lr_scheduler])","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:45:54.811055Z","iopub.execute_input":"2023-07-18T13:45:54.811664Z","iopub.status.idle":"2023-07-18T13:58:36.674150Z","shell.execute_reply.started":"2023-07-18T13:45:54.811627Z","shell.execute_reply":"2023-07-18T13:58:36.672931Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1278/1278 [==============================] - 200s 142ms/step - loss: 2.0452e-07 - accuracy: 0.0251 - val_loss: 2.3957e-07 - val_accuracy: 0.0247 - lr: 0.0010\nEpoch 2/50\n1278/1278 [==============================] - 182s 140ms/step - loss: 2.0452e-07 - accuracy: 0.0245 - val_loss: 2.3957e-07 - val_accuracy: 0.0249 - lr: 0.0010\nEpoch 3/50\n1278/1278 [==============================] - 182s 140ms/step - loss: 2.0452e-07 - accuracy: 0.0251 - val_loss: 2.3957e-07 - val_accuracy: 0.0253 - lr: 0.0010\nEpoch 4/50\n1278/1278 [==============================] - 194s 149ms/step - loss: 2.0452e-07 - accuracy: 0.0249 - val_loss: 2.3957e-07 - val_accuracy: 0.0238 - lr: 1.0000e-04\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7b10c87dbca0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing for a random image","metadata":{}},{"cell_type":"code","source":"import random\nfrom tensorflow.keras.preprocessing import image as keras_image\nimport numpy as np\n\ndef load_image(image_path, target_size=(224, 224)):\n    img = keras_image.load_img(image_path, target_size=target_size)\n    img_tensor = keras_image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor = tf.keras.applications.resnet.preprocess_input(img_tensor)\n    return img_tensor\n\n# Randomly select an image from validation set\nrandom_image_path = random.choice(val_df['filename'].tolist())\n\n# Load the image\ntest_image = load_image(random_image_path)\n\n# Use the model to predict the steering angle for the test image\npredicted_angle = model.predict(test_image)\n\n# Print out the predicted steering angle\nprint(\"Predicted steering angle: \", predicted_angle[0][0])\n\n# If you want to compare this prediction to the actual angle, you could find that as follows:\nactual_angle = val_df[val_df['filename'] == random_image_path]['steering_angle'].values[0]\nprint(\"Actual steering angle: \", actual_angle)","metadata":{"execution":{"iopub.status.busy":"2023-07-18T13:58:36.676963Z","iopub.execute_input":"2023-07-18T13:58:36.678317Z","iopub.status.idle":"2023-07-18T13:58:37.056372Z","shell.execute_reply.started":"2023-07-18T13:58:36.678274Z","shell.execute_reply":"2023-07-18T13:58:37.055154Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 283ms/step\nPredicted steering angle:  1.2313507\nActual steering angle:  1.11\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-07-18T14:15:55.212249Z","iopub.execute_input":"2023-07-18T14:15:55.213430Z","iopub.status.idle":"2023-07-18T14:15:56.350435Z","shell.execute_reply.started":"2023-07-18T14:15:55.213388Z","shell.execute_reply":"2023-07-18T14:15:56.349173Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"fatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}