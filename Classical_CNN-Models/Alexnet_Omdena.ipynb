{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "img_dir = '/content/Omdena-Quantum-Self-Driving/Images/driving_dataset1/'\n",
    "root_img = '/content/Omdena-Quantum-Self-Driving/Images/driving_dataset1/'\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "\n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]\n",
    "            if len(data)==0:\n",
    "               raise TypeError(\"issue reading jpeg file\")\n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(img_dir):\n",
    "    imagesList = fileList\n",
    "    for img in tqdm(imagesList):\n",
    "      image = os.path.join(root_img,img)\n",
    "      image = JPEG(image)\n",
    "      try:\n",
    "        image.decode()\n",
    "      except:\n",
    "        bads.append(img)\n",
    "\n",
    "\n",
    "for name in bads:\n",
    "  os.remove(os.path.join(root_img,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>steering_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Images/driving_dataset1/0.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Images/driving_dataset1/1.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Images/driving_dataset1/2.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Images/driving_dataset1/3.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Images/driving_dataset1/4.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  steering_angle\n",
       "0  ../Images/driving_dataset1/0.jpg             0.0\n",
       "1  ../Images/driving_dataset1/1.jpg             0.0\n",
       "2  ../Images/driving_dataset1/2.jpg             0.0\n",
       "3  ../Images/driving_dataset1/3.jpg             0.0\n",
       "4  ../Images/driving_dataset1/4.jpg             0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load steering angles from text file\n",
    "df = pd.read_csv('../Images/driving_dataset1/data.txt', names=['filename', 'steering_angle'], delimiter=' ')\n",
    "image_dir = '../Images/driving_dataset1/'\n",
    "data_file = \"../Images/driving_dataset1/data.txt\"\n",
    "df['filename'] = df['filename'].apply(lambda x: os.path.join(image_dir, x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (224, 224))\n",
    "        image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    except:\n",
    "        print(f\"Invalid image format, skipping: {image_path}\")\n",
    "        return None\n",
    "    return image\n",
    "\n",
    "def create_dataset(df):\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(df['filename'])\n",
    "    angle_dataset = tf.data.Dataset.from_tensor_slices(df['steering_angle'])\n",
    "    image_dataset = image_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    image_dataset = image_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, angle_dataset))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "def resnet_model(input_shape):\n",
    "    base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def alexnet_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(tf.keras.layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(tf.keras.layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(tf.keras.layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 5\n",
    "    model.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Flatten the output from previous layers\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Layer 6\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/l1/6vjdp8yj0n3_zw7vxxnh__3m0000gn/T/ipykernel_28443/3298985671.py:16: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.1\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "val_df = df[:int(validation_split*len(df))]\n",
    "train_df = df[int(validation_split*len(df)):]\n",
    "\n",
    "train_dataset = create_dataset(train_df)\n",
    "val_dataset = create_dataset(val_df)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "model = alexnet_model((224, 224, 3))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1278/1278 [==============================] - 2172s 2s/step - loss: 11.3466 - val_loss: 8.2430\n",
      "Epoch 2/25\n",
      "1278/1278 [==============================] - 4197s 3s/step - loss: 7.7660 - val_loss: 6.8449\n",
      "Epoch 3/25\n",
      "1278/1278 [==============================] - 4236s 3s/step - loss: 6.4845 - val_loss: 5.6926\n",
      "Epoch 4/25\n",
      "1278/1278 [==============================] - 4011s 3s/step - loss: 5.6155 - val_loss: 4.9754\n",
      "Epoch 5/25\n",
      "1278/1278 [==============================] - 4134s 3s/step - loss: 4.7554 - val_loss: 4.0661\n",
      "Epoch 6/25\n",
      "1278/1278 [==============================] - 7817s 6s/step - loss: 3.9769 - val_loss: 4.1429\n",
      "Epoch 7/25\n",
      "1278/1278 [==============================] - 7423s 6s/step - loss: 3.4057 - val_loss: 3.2109\n",
      "Epoch 8/25\n",
      "1278/1278 [==============================] - 6110s 5s/step - loss: 2.9678 - val_loss: 2.8537\n",
      "Epoch 9/25\n",
      "1278/1278 [==============================] - 2177s 2s/step - loss: 2.6532 - val_loss: 2.6051\n",
      "Epoch 10/25\n",
      "1278/1278 [==============================] - 2144s 2s/step - loss: 2.4566 - val_loss: 2.4064\n",
      "Epoch 11/25\n",
      "1278/1278 [==============================] - 3322s 3s/step - loss: 2.3327 - val_loss: 2.2478\n",
      "Epoch 12/25\n",
      "1278/1278 [==============================] - 8703s 7s/step - loss: 2.2130 - val_loss: 2.2790\n",
      "Epoch 13/25\n",
      "1278/1278 [==============================] - 11676s 9s/step - loss: 2.1257 - val_loss: 2.0870\n",
      "Epoch 14/25\n",
      "1278/1278 [==============================] - 6468s 5s/step - loss: 2.0582 - val_loss: 2.1929\n",
      "Epoch 15/25\n",
      "1278/1278 [==============================] - 7707s 6s/step - loss: 1.9928 - val_loss: 2.3029\n",
      "Epoch 16/25\n",
      "1278/1278 [==============================] - 10881s 9s/step - loss: 1.9348 - val_loss: 2.3363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13b8ac130>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=25, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m random_image_path \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(val_df[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     15\u001b[0m \u001b[39m# Load the image\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m test_image \u001b[39m=\u001b[39m load_image(random_image_path)\n\u001b[1;32m     18\u001b[0m \u001b[39m# Use the model to predict the steering angle for the test image\u001b[39;00m\n\u001b[1;32m     19\u001b[0m predicted_angle \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_image)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(image_path, target_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(image_path, target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)):\n\u001b[0;32m----> 6\u001b[0m     img \u001b[39m=\u001b[39m keras_image\u001b[39m.\u001b[39;49mload_img(image_path, target_size\u001b[39m=\u001b[39;49mtarget_size)\n\u001b[1;32m      7\u001b[0m     img_tensor \u001b[39m=\u001b[39m keras_image\u001b[39m.\u001b[39mimg_to_array(img)\n\u001b[1;32m      8\u001b[0m     img_tensor \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(img_tensor, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/image_utils.py:414\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    412\u001b[0m     color_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, io\u001b[39m.\u001b[39mBytesIO):\n\u001b[1;32m    418\u001b[0m     img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(path)\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "\n",
    "def load_image(image_path, target_size=(224, 224)):\n",
    "    img = keras_image.load_img(image_path, target_size=target_size)\n",
    "    img_tensor = keras_image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    img_tensor = tf.keras.applications.resnet.preprocess_input(img_tensor)\n",
    "    return img_tensor\n",
    "\n",
    "# Randomly select an image from validation set\n",
    "random_image_path = random.choice(val_df['filename'].tolist())\n",
    "\n",
    "# Load the image\n",
    "test_image = load_image(random_image_path)\n",
    "\n",
    "# Use the model to predict the steering angle for the test image\n",
    "predicted_angle = model.predict(test_image)\n",
    "\n",
    "# Print out the predicted steering angle\n",
    "print(\"Predicted steering angle: \", predicted_angle[0][0])\n",
    "\n",
    "# If you want to compare this prediction to the actual angle, you could find that as follows:\n",
    "actual_angle = val_df[val_df['filename'] == random_image_path]['steering_angle'].values[0]\n",
    "print(\"Actual steering angle: \", actual_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
